# Docker Compose for Cortex Suite - Flexible Volume Mounting
# This version allows mounting any host directory for document ingestion
version: '3.8'

services:
  # Ollama Service for Local LLM
  ollama:
    image: ollama/ollama:latest
    container_name: cortex-ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_ORIGINS=*
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    profiles:
      - gpu
      - cpu

  # ChromaDB Vector Database
  chromadb:
    image: chromadb/chroma:latest
    container_name: cortex-chromadb
    restart: unless-stopped
    volumes:
      - chroma_data:/chroma/chroma
    ports:
      - "8001:8000"
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Cortex API Service
  cortex-api:
    build:
      context: ..
      dockerfile: docker/Dockerfile.api
    container_name: cortex-api
    restart: unless-stopped
    depends_on:
      chromadb:
        condition: service_healthy
      ollama:
        condition: service_healthy
    volumes:
      # Persistent data storage
      - cortex_data:/data
      - cortex_logs:/app/logs
      
      # FLEXIBLE MOUNTING: Uncomment and modify these lines to mount host directories
      # Replace /path/to/your/documents with the actual path on your host system
      
      # Example: Mount entire home directory (READ-ONLY for safety)
      # - ${HOME}:/host/home:ro
      
      # Example: Mount specific document folders
      # - /path/to/your/documents:/host/documents:ro
      # - /path/to/another/folder:/host/projects:ro
      
      # Example: Mount Windows drives (if using Docker Desktop on Windows)
      # - C:\Users\YourUser\Documents:/host/documents:ro
      # - D:\Projects:/host/projects:ro
      
      # Example: Mount external drives
      # - /media/external-drive:/host/external:ro
      # - /mnt/network-drive:/host/network:ro
      
    ports:
      - "8000:8000"  
    environment:
      - AI_DATABASE_PATH=/data/ai_databases
      - KNOWLEDGE_SOURCE_PATH=/data/knowledge_base
      # Add paths that will be accessible inside container
      - HOST_MOUNT_PATHS=/host/documents,/host/projects,/host/home,/host/external,/host/network
      - LLM_PROVIDER=ollama
      - OLLAMA_BASE_URL=http://ollama:11434
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Cortex Streamlit UI
  cortex-ui:
    build:
      context: ..
      dockerfile: docker/Dockerfile.ui
    container_name: cortex-ui
    restart: unless-stopped
    depends_on:
      cortex-api:
        condition: service_healthy
    volumes:
      # Persistent data storage
      - cortex_data:/data
      - cortex_logs:/app/logs
      
      # FLEXIBLE MOUNTING: Same mounts as API service for consistency
      # Uncomment and modify these lines to match your API service mounts
      
      # Example: Mount entire home directory (READ-ONLY for safety)  
      # - ${HOME}:/host/home:ro
      
      # Example: Mount specific document folders
      # - /path/to/your/documents:/host/documents:ro
      # - /path/to/another/folder:/host/projects:ro
      
      # Example: Mount Windows drives (if using Docker Desktop on Windows)
      # - C:\Users\YourUser\Documents:/host/documents:ro
      # - D:\Projects:/host/projects:ro
      
      # Example: Mount external drives
      # - /media/external-drive:/host/external:ro
      # - /mnt/network-drive:/host/network:ro
      
    ports:
      - "8501:8501"
    environment:
      - AI_DATABASE_PATH=/data/ai_databases
      - KNOWLEDGE_SOURCE_PATH=/data/knowledge_base
      # Add paths that will be accessible inside container
      - HOST_MOUNT_PATHS=/host/documents,/host/projects,/host/home,/host/external,/host/network
      - API_BASE_URL=http://cortex-api:8000
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Model Initialization Service (runs once)
  model-init:
    build:
      context: ..
      dockerfile: docker/Dockerfile.init
    container_name: cortex-model-init
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    command: |
      sh -c "
        echo 'Pulling Ollama models...'
        curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"mistral:7b-instruct-v0.3-q4_K_M\"}'
        curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"mistral-small3.2\"}'
        echo 'Models pulled successfully'
      "
    restart: "no"

volumes:
  ollama_data:
    driver: local
  chroma_data:
    driver: local
  cortex_data:
    driver: local
  cortex_logs:
    driver: local

networks:
  default:
    name: cortex-network